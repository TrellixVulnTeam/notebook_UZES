

## requests模块

    1. get方法
        1. get(url, headers={})
            发情请求，并获取响应对象

        get() 使用场景
            1. 没有查询参数
                res = request.get(url, headers={})
            2. 有查询参数（params）
                res = requests.get(
                    url,
                    params=params,
                    headers=headers
                )

    2. post方法
        post(url, data=data, headers=headers)
            data: Form表单数据，字典, 不用编码也不用转码

    3. 使用代理
        普通代理
            格式：proxies={
                    '协议': '协议://ip地址:端口号',
                 }

             proxies = {
                'http': 'http://xxx.xxx.xxx.xx:port'
             }

        私密代理
            格式
                proxies = {
                    'http': 'http://用户名:密码@ip地址:端口号'
                }

响应对象的属性:


```
response.status_code   状态码
response.url           请求url
response.encoding   查看响应头部字符编码
response.cookies    cookie信息
response.headers    头信息
response.text       文本形式的响应内容
response.content    二进制字节形式的响应内容
response.json()     JSON形式的响应内容(其实就是dict字典类型)
```


## Xpath 工具

1. xpath

在xml文档中查找信息的语言，同样适用于HTML文档检索

2. xpath辅助工具

    Chrome插件：Xpath Helper
    打开：Ctrl + Shift + X
    Firefox 插件： Xpath checker

3. X匹配规则

    1. 匹配演示
        1. 匹配bookstore下所有节点 /bookstore
        2. 查找所有的book节点 // book
        3. 查找bookstore下的所有book节点  /bookstore/book
        4. 查找所有book节点下的title节点中，lang属性为'en'的节点：
            //book/title[@lang='en']
        5. 查找bookstore下的第2个book节点下的title节点
            /bookstore/book[2]/title    /text()

    2. 选取节点

        /: 从根节点开始选取

        //: 从整个文档中查找节点
            //price      //bookstore/book//price

        @: 选取某个节点
            //div[@class="movie-info"]/a[@class="name"]

        @: 获取某个节点的属性值
            获取所有book下的title节点的lang属性的值
            //book/title/@lang
            <a href="http://www.xxxx.com/"></a>

4. 匹配多路径

    符号： |

    获取所有book节点下的title节点和price节点

    //book/title | //book/price

5. 函数

    contains()
        匹配1个属性值中包含某个字符串的节点

        所有的title节点中lang属性值包含ch的节点
        //title[contains(@lang, 'ch')]

    text()
        //title[contains(@lang,'ch')]/text()



## lxml库及xpath使用

    lxml库：HTML/XML解析库

    使用流程
        导入模块 from lxml import etree
        创建解析对象 parse_hmtl = etree.HTML(html)
        调用xpath：items = parse_html.xpath('xpath表达式')


## json 模块

    javascript中的对象和数组
    对象：{'key': 'value'}
    数组：[x1, x2, x3]

    作用
        json格式的字符串 和 python数据类型之间的转换

    常用的一些方法
        json.loads(): 把json格式的转为python的数据类型
            json     python
            对象      字典
            数组      列表

        json.dumps(): 把python的数据类型转为json格式
            python   json
            字典      对象
            列表      数组
            元组      数组

        ## 注意
            json.dumps() 默认使用ascii 编码
            添加参数 ensure_ascii=False 禁用ascii编码


## 动态网站数据抓取 - AJAX动态加载

    1. 特点： 滚动鼠标滑轮时才会加载
        完整的查询参数，F12 - Query String Paramters
        发送请求时要写F12抓到的Request URL的地址
    2. 案例： 豆瓣电影排行榜数据抓取
        1. 网址
        2. 目标

    3. selenium + phantomjs 强大的网络爬虫组合
        selenium:
            定义： web自动化测试工具，应用于web自动化测试
            特点： 可以运行在浏览器上，根据指令命令操作浏览器，让浏览器自动加载页面
                    只是一个工具，不支持浏览器功能，需要与第三方浏览器结合使用

        phantomjs:
            定义：无界面的浏览器
            特点：把网站加载到内存再进行页面的加载，运行高效
            安装
                window: 将下载的可执行文件放到python安装目录的scripts目录下
        示例:
            phantomjs.py   chromedriver.py

        常用方法
            driver.get(url)
            driver.page_source: 获取响应的html的源码
            driver.page_source.find('字符串')
                  -1: 查找失败
                非-1: 查找成功
            单元素查找
                driver.find_element_by_id("")
                driver.find_element_by_class_name("")
                driver.find_element_by_xpath("xpath表达式")
                只匹配第一个符合条件的节点对象

            多元素查找
                driver.find_elements_by_id("")
                driver.find_elements_by_class_name("")
                driver.find_elements_by_xpath("xpath表达式")

            对象名.send_keys('内容')
            对象名.click()
            对象名.text
                获取节点对象的文本内容

    4. Chromedriver 设置无界面模式
        opt = webdriver.ChromeOptions()
        opt.set_headless()
        driver = webdriver.Chrome(options=opt)

        ## ChromeOptions() 对象可添加各种功能
            比如说： 无界面，浏览器分辨率
            opt.set_headless()
            opt.add_argument('window-size=1900x3000')


    JS分页网站案例
        斗鱼直播主播信息抓取
        抓取目标：
                主播名字: xpath: //ul[@id="live-list-contentbox"]//span[@class="dy-name ellipsis fl"]
                关注数量: xpath: //ul[@id="live-list-contentbox"]//span[@class="dy-num fr"]


## 示例脚本

### phantomjs

```python title="phantomjs.py"
#encoding: utf-8

from selenium import webdriver

# 创建phantomjs浏览器对象
driver = webdriver.PhantomJS()

# 向网站发请求
driver.get('http://www.baidu.com')

# 打印响应html源码
print(driver.page_source)

# 获取内存里网页的截屏
driver.save_screenshot('百度.png')

# 关闭浏览器
driver.quit()
```

### chromedriver

```python title="chromedriver.py"
#encoding: utf-8
import time

from selenium import webdriver

# 创建浏览器对象
driver = webdriver.PhantomJS()

# 向百度发请求
driver.get('http://www.baidu.com/')

# 向百度搜索框里发送内容
driver.find_element_by_id('kw').send_keys('美女')

# 点击搜索按钮
driver.find_element_by_id('su').click()

time.sleep(3)
# 截图
driver.save_screenshot('美女.png')

# 关闭浏览器
driver.quit()
```

### 爬取彼岸壁纸

```python title="爬取彼岸壁纸"
#!/bin/python3
#Author: yiouejv
#Email: yiouejv@126.com
#Time: 2022-06-23 10:31:01
#Name: bizhi.py


'''下载流程
# domain: https://pic.netbian.com
# 高清壁纸相对地址: //ul[@class="clearfix"]/li/a[contains(@href, "tupian")]/@href

# 来到壁纸界面，发送ajax请求，得到壁纸的真实地址: pic
    {msg: 4, pic: "/downpic.php?id=25836&classid=66"}
    :authority: pic.netbian.com
    :method: GET
    :path: /e/extend/downpic.php?id=25836&t=0.18061702007987468
    :scheme: https
    accept: application/json, text/javascript, */*; q=0.01
    accept-encoding: gzip, deflate, br
    accept-language: zh-CN,zh;q=0.9,en;q=0.8
    cache-control: no-cache
    cookie: __yjs_duid=1_2fbde9830d63e687d26ffd5dbcc46d6f1631165275412; Hm_lvt_14b14198b6e26157b7eba06b390ab763=1639719384,1641981179; Hm_lpvt_14b14198b6e26157b7eba06b390ab763=1641981203; zkhanecookieclassrecord=%2C54%2C66%2C; Hm_lvt_0f461eb489c245a31c209d36e41fcc0f=1655950819; Hm_lpvt_0f461eb489c245a31c209d36e41fcc0f=1655950829; Hm_lvt_c59f2e992a863c2744e1ba985abaea6c=1655950831; PHPSESSID=ivpqjeqb8t4bifn5oufe17fa10; zkhanmlusername=%C0%E1%D1%DB%EB%FC%EB%CA; zkhanmluserid=2091288; zkhanmlgroupid=3; zkhanmlrnd=dUu0S5IRkrJwkj8SWWqm; zkhanmlauth=3b38931b4075a774ca15d7725012cc47; Hm_lvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_c59f2e992a863c2744e1ba985abaea6c=1655952060; zkhandownid25836=1
    pragma: no-cache
    referer: https://pic.netbian.com/tupian/25836.html
    sec-ch-ua: " Not A;Brand";v="99", "Chromium";v="102", "Google Chrome";v="102"
    sec-ch-ua-mobile: ?0
    sec-ch-ua-platform: "Windows"
    sec-fetch-dest: empty
    sec-fetch-mode: cors
    sec-fetch-site: same-origin
    user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36
    x-requested-with: XMLHttpRequest

# https://pic.netbian.com/downpic.php?id=25836&classid=66
    :authority: pic.netbian.com
    :method: GET
    :path: /downpic.php?id=25836&classid=66
    :scheme: https
    accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
    accept-encoding: gzip, deflate, br
    accept-language: zh-CN,zh;q=0.9,en;q=0.8
    cache-control: no-cache
    cookie: __yjs_duid=1_2fbde9830d63e687d26ffd5dbcc46d6f1631165275412; Hm_lvt_14b14198b6e26157b7eba06b390ab763=1639719384,1641981179; Hm_lpvt_14b14198b6e26157b7eba06b390ab763=1641981203; zkhanecookieclassrecord=%2C54%2C66%2C; Hm_lvt_0f461eb489c245a31c209d36e41fcc0f=1655950819; Hm_lpvt_0f461eb489c245a31c209d36e41fcc0f=1655950829; Hm_lvt_c59f2e992a863c2744e1ba985abaea6c=1655950831; PHPSESSID=ivpqjeqb8t4bifn5oufe17fa10; zkhanmlusername=%C0%E1%D1%DB%EB%FC%EB%CA; zkhanmluserid=2091288; zkhanmlgroupid=3; zkhanmlrnd=dUu0S5IRkrJwkj8SWWqm; zkhanmlauth=3b38931b4075a774ca15d7725012cc47; Hm_lvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_c59f2e992a863c2744e1ba985abaea6c=1655952060; zkhandownid25836=1
    pragma: no-cache
    referer: https://pic.netbian.com/tupian/25836.html
    sec-ch-ua: " Not A;Brand";v="99", "Chromium";v="102", "Google Chrome";v="102"
    sec-ch-ua-mobile: ?0
    sec-ch-ua-platform: "Windows"
    sec-fetch-dest: iframe
    sec-fetch-mode: navigate
    sec-fetch-site: same-origin
    upgrade-insecure-requests: 1
    user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36
'''

import requests
import json
from lxml import etree
from hyper.contrib import HTTP20Adapter
from time import sleep
import re


def get_index_url(page):
    if page == 1:
        return  "https://pic.netbian.com/"
    return "https://pic.netbian.com/index_{}.html".format(page)


def get_pic_href_list(page):
    url = get_index_url(page)

    headers = {
        r":authority": "pic.netbian.com",
        ":method": "GET",
        ":path": "/",
        ":scheme": "https",
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9",
        "accept-encoding": "gzip, deflate, br",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "cache-control": "no-cache",
        "cookie": "__yjs_duid=1_2fbde9830d63e687d26ffd5dbcc46d6f1631165275412; Hm_lvt_14b14198b6e26157b7eba06b390ab763=1639719384,1641981179; Hm_lpvt_14b14198b6e26157b7eba06b390ab763=1641981203; zkhanecookieclassrecord=%2C54%2C66%2C; Hm_lvt_0f461eb489c245a31c209d36e41fcc0f=1655950819; Hm_lpvt_0f461eb489c245a31c209d36e41fcc0f=1655950829; Hm_lvt_c59f2e992a863c2744e1ba985abaea6c=1655950831; PHPSESSID=ivpqjeqb8t4bifn5oufe17fa10; zkhanmlusername=%C0%E1%D1%DB%EB%FC%EB%CA; zkhanmluserid=2091288; zkhanmlgroupid=3; zkhanmlrnd=dUu0S5IRkrJwkj8SWWqm; zkhanmlauth=3b38931b4075a774ca15d7725012cc47; Hm_lvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_c59f2e992a863c2744e1ba985abaea6c=1655953106",
        "pragma": "no-cache",
        "sec-ch-ua": '" Not A;Brand";v="99", "Chromium";v="102", "Google Chrome";v="102"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "Windows",
        "sec-fetch-dest": "document",
        "sec-fetch-mode": "navigate",
        "sec-fetch-site": "none",
        "sec-fetch-user": "?1",
        "referer" : "",
        "upgrade-insecure-requests": "1",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36"
    }
    if page == 1:
        headers[":path"] = "/"
        del headers["referer"]
    else:
        headers[":path"] = "/index_{}.html".format(page)
        headers["referer"] = get_index_url(page - 1)

    session = requests.session()
    session.mount("https://pic.netbian.com", HTTP20Adapter())
    res = session.get(url, headers=headers)
    res.encoding = "utf-8"
    if res.status_code == 200:
        parse_html = etree.HTML(res.text)
        hrefs = parse_html.xpath('''//ul[@class="clearfix"]/li/a[contains(@href, "tupian")]/@href''')
        print(page, hrefs)
        return hrefs
    else:
        print(res)


def only_open_url(url, rela_url, page):
    # 打开一次url，什么都不做
    headers = {
        ":authority": "pic.netbian.com",
        ":method": "GET",
        ":path": "/tupian/29358.html",
        ":scheme": "https",
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9",
        "accept-encoding": "gzip, deflate, br",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "cache-control": "no-cache",
        "cookie": "__yjs_duid=1_2fbde9830d63e687d26ffd5dbcc46d6f1631165275412; Hm_lvt_14b14198b6e26157b7eba06b390ab763=1639719384,1641981179; Hm_lpvt_14b14198b6e26157b7eba06b390ab763=1641981203; zkhanecookieclassrecord=%2C54%2C66%2C; Hm_lvt_0f461eb489c245a31c209d36e41fcc0f=1655950819; Hm_lpvt_0f461eb489c245a31c209d36e41fcc0f=1655950829; Hm_lvt_c59f2e992a863c2744e1ba985abaea6c=1655950831; PHPSESSID=ivpqjeqb8t4bifn5oufe17fa10; zkhanmlusername=%C0%E1%D1%DB%EB%FC%EB%CA; zkhanmluserid=2091288; zkhanmlgroupid=3; zkhanmlrnd=dUu0S5IRkrJwkj8SWWqm; zkhanmlauth=3b38931b4075a774ca15d7725012cc47; Hm_lvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_c59f2e992a863c2744e1ba985abaea6c=1655955982",
        "pragma": "no-cache",
        "referer": "https://pic.netbian.com/",
        "sec-ch-ua": '''" Not A;Brand";v="99", "Chromium";v="102", "Google Chrome";v="102"''',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "Windows",
        "sec-fetch-dest": "document",
        "sec-fetch-mode": "navigate",
        "sec-fetch-site": "same-origin",
        "sec-fetch-user": "?1",
        "upgrade-insecure-requests": "1",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36",
    }
    headers[":path"] = rela_url
    headers["referer"] = get_index_url(page - 1)
    get_response(url, headers)


def get_response(url, headers, encoding="utf-8"):
    session = requests.session()
    session.mount("https://pic.netbian.com", HTTP20Adapter())
    res = session.get(url, headers=headers)
    res.encoding = encoding
    return res


def get_really_down_url(url, pid):
    headers = {
            ":authority": "pic.netbian.com",
            ":method": "GET",
            ":path": "/e/extend/downpic.php?id=25836&t=0.18061702007987468",
            ":scheme": "https",
            "accept": "application/json, text/javascript, */*; q=0.01",
            "accept-encoding": "gzip, deflate, br",
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
            "cache-control": "no-cache",
            "cookie": "__yjs_duid=1_2fbde9830d63e687d26ffd5dbcc46d6f1631165275412; Hm_lvt_14b14198b6e26157b7eba06b390ab763=1639719384,1641981179; Hm_lpvt_14b14198b6e26157b7eba06b390ab763=1641981203; zkhanecookieclassrecord=%2C54%2C66%2C; Hm_lvt_0f461eb489c245a31c209d36e41fcc0f=1655950819; Hm_lpvt_0f461eb489c245a31c209d36e41fcc0f=1655950829; Hm_lvt_c59f2e992a863c2744e1ba985abaea6c=1655950831; PHPSESSID=ivpqjeqb8t4bifn5oufe17fa10; zkhanmlusername=%C0%E1%D1%DB%EB%FC%EB%CA; zkhanmluserid=2091288; zkhanmlgroupid=3; zkhanmlrnd=dUu0S5IRkrJwkj8SWWqm; zkhanmlauth=3b38931b4075a774ca15d7725012cc47; Hm_lvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_c59f2e992a863c2744e1ba985abaea6c=1655952060; zkhandownid25836=1",
            "pragma": "no-cache",
            "referer": "https://pic.netbian.com/tupian/25836.html",
            "sec-ch-ua": '''" Not A;Brand";v="99", "Chromium";v="102", "Google Chrome";v="102"''',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "Windows",
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36",
            "x-requested-with": "XMLHttpRequest",
        }
    headers["referer"] = url
    headers[":path"] = "/e/extend/downpic.php?id={}&t=0.18061702007987468".format(pid)
    res = get_response(url, headers)
    if res.status_code == 200:
        return res.json()["pic"]
    else:
        print("get_really_down_url err:", res.text, url)


def download_img(url, rela_url, pid, page):
    only_open_url(url, rela_url, page)
    really_url = get_really_down_url(url, pid)
    if really_url:
        headers = {
            ":authority": "pic.netbian.com",
            ":method": "GET",
            ":path": "/downpic.php?id=25836&classid=66",
            ":scheme": "https",
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9",
            "accept-encoding": "gzip, deflate, br",
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
            "cache-control": "no-cache",
            "cookie": "__yjs_duid=1_2fbde9830d63e687d26ffd5dbcc46d6f1631165275412; Hm_lvt_14b14198b6e26157b7eba06b390ab763=1639719384,1641981179; Hm_lpvt_14b14198b6e26157b7eba06b390ab763=1641981203; zkhanecookieclassrecord=%2C54%2C66%2C; Hm_lvt_0f461eb489c245a31c209d36e41fcc0f=1655950819; Hm_lpvt_0f461eb489c245a31c209d36e41fcc0f=1655950829; Hm_lvt_c59f2e992a863c2744e1ba985abaea6c=1655950831; PHPSESSID=ivpqjeqb8t4bifn5oufe17fa10; zkhanmlusername=%C0%E1%D1%DB%EB%FC%EB%CA; zkhanmluserid=2091288; zkhanmlgroupid=3; zkhanmlrnd=dUu0S5IRkrJwkj8SWWqm; zkhanmlauth=3b38931b4075a774ca15d7725012cc47; Hm_lvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_526caf4e20c21f06a4e9209712d6a20e=1655951690; Hm_lpvt_c59f2e992a863c2744e1ba985abaea6c=1655952060; zkhandownid25836=1",
            "pragma": "no-cache",
            "referer": "https://pic.netbian.com/tupian/25836.html",
            "sec-ch-ua": '''" Not A;Brand";v="99", "Chromium";v="102", "Google Chrome";v="102"''',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "Windows",
            "sec-fetch-dest": "iframe",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "same-origin",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36",
        }
        print(really_url)
        headers[":path"] = really_url
        headers["referer"] = url
        res = get_response("https://pic.netbian.com" + really_url, headers, encoding="gbk")

        with open("E:\\彼岸壁纸\\{}.jpg".format(pid), "wb") as wf:
            wf.write(res.content)
            print(pid, " success")


def main():
    for i in range(2, 1032):
        img_rela_urls = get_pic_href_list(i)
        for url in img_rela_urls:
            img_url = "https://pic.netbian.com{}".format(url)
            pid = re.findall(r"/tupian/(\d+).html", url)[0]
            download_img(img_url, url, pid, i)
            sleep(0.5)

        sleep(0.5)


if __name__ == "__main__":
    main()
```
